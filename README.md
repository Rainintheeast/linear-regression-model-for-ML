# linear-regression-model-for-ML
Machine learning introductory training

学习机器学习（Machine Learning，ML）是一个步骤很多的过程，通常包括理解基本概念、学习相关算法和库，以及实际应用在数据上。Python 是进行机器学习的主流语言，有很多有用的库，例如 scikit-learn、TensorFlow 和 PyTorch。

这里是一个简单的使用 scikit-learn 的线性回归示例。在这个示例中，我们首先导入了所需的库，然后生成了一些随机数据。我们将数据分为训练集和测试集，然后创建了一个线性回归模型。我们在训练集上训练模型，然后在测试集上评估模型的性能。

![1697647314618](https://github.com/Rainintheeast/linear-regression-model-for-ML/assets/80569437/b62ec08c-b262-4b2f-8068-384b700161f6)

![1697647337448](https://github.com/Rainintheeast/linear-regression-model-for-ML/assets/80569437/5f79cad5-a11b-47b6-a6c9-8c3a260fbe0c)

在 scikit-learn 库中，`fit` 方法用于训练模型。具体来说，它将算法应用于提供的数据，以找到最佳化模型参数的过程。在线性回归的情况下，这意味着它会寻找一条最佳拟合线，使得所有数据点到这条线的平方距离之和最小。

以下是`fit`方法的基本步骤：

1. **参数初始化**:
   首先，模型的参数（在线性回归中是斜率和截距）被初始化。这可能是随机的，或者是基于一些启发式的选择。

2. **损失计算**:
   接下来，计算模型对于训练数据的预测误差，通常通过一个损失函数来完成。在线性回归中，通常使用均方误差（Mean Squared Error，MSE）作为损失函数。

3. **优化**:
   然后，使用一种优化算法（如梯度下降）来调整模型的参数，以最小化损失函数。

4. **收敛检查**:
   检查是否达到了停止条件（例如，损失函数的改变小于某个阈值，或者达到了最大迭代次数）。如果满足停止条件，则停止优化；否则，返回到第2步，并继续优化。

在调用 `fit` 方法时，需要传递训练数据（特征和目标变量）作为参数。例如，在线性回归的例子中：

```python
lin_reg.fit(X_train, y_train)
```

其中 `X_train` 是训练特征，`y_train` 是训练目标变量。通过调用 `fit` 方法，`lin_reg` 对象现在包含了优化过的模型参数，可以用于对新数据进行预测。


`test_size` 参数在 scikit-learn 的 `train_test_split` 函数中用于指定应保留多少数据用于测试集，而剩余的数据则用于训练集。`test_size` 的选择可能会受到多种因素的影响，包括数据的总量、问题的复杂性和特定的项目需求。以下是一些通常的考虑因素和指南：

1. **数据量**:
   - 如果你的数据量很大（例如，数十万或数百万条记录），则可能只需要一个较小的测试集，例如 10% 或 20%。
   - 如果数据量较小，可能需要一个较大的测试集，例如 30% 或 40%，以确保测试结果的可靠性。

2. **问题复杂性**:
   - 对于复杂的问题，可能希望有一个较大的测试集来评估模型的性能。
   
3. **计算资源**:
   - 如果计算资源有限，可能会选择一个较小的测试集来减少测试的时间和成本。

4. **项目需求**:
   - 项目的具体需求可能会影响 `test_size` 的选择。例如，如果需要非常准确的模型，可能会选择一个较大的测试集来进行更严格的评估。

通常的选择包括：

- `test_size=0.2` 或 `0.25`：这意味着 20% 或 25% 的数据将被保留为测试集，而其余的将用于训练集。
- `test_size=0.3` 或 `0.33`：这意味着 30% 或 33% 的数据将被保留为测试集。

这些选择提供了一个合理的训练/测试分割，同时还保留了足够的数据来评估模型的性能。

最终，`test_size` 的最佳值可能会因项目而异。可能需要尝试不同的值，以找到适合特定问题和数据集的最佳分割。


均方误差（Mean Squared Error，MSE）是衡量模型预测错误的一种常用指标。它是观测值和模型预测值之间差值的平方的平均值。具体来说，对于 n 个数据点，均方误差的公式为：

$\[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]$

其中：
- $\( n \)$ 是数据点的数量。
- $\( y_i \)$ 是第 i 个数据点的实际值。
- $\( \hat{y}_i \)$ 是第 i 个数据点的预测值。

MSE 的特点包括：

1. **非负值**：由于是平方的计算，MSE 的值永远是非负的。MSE 的最小值为 0，这意味着模型的预测完全准确。

2. **惩罚大误差**：由于误差被平方，所以较大的误差会受到更严重的惩罚。这使得 MSE 对于异常值非常敏感。

3. **可解释性**：MSE 的单位是目标变量单位的平方，这可能会使得解释困难。例如，如果目标变量是以美元为单位，那么 MSE 就是以美元的平方为单位，这可能不是很直观。

在机器学习和统计学中，MSE 是一种常用的性能度量，它提供了一种量化模型预测误差的方法。它尤其在回归问题中非常常见，但也可以用于其他类型的模型评估
